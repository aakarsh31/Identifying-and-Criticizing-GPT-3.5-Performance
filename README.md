This project aims to define OpenAI’s ChatGPT chatbot from a poetic/opinion-based sense of view. The main question we would like to ask here is “Can GPT duplicate the responses of humans in areas of little statistic knowledge and more of human opinion-based domains like sentimental analysis or poetic analysis and classification?”. 

We then proceed further to judge what metrics can an AI model be compared to a real-life human keeping in mind that each human has different opinions. Every human's opinions also change with time, making it harder to judge an AI model accurately. 

TEMPERATURE

The concept of Temperature determines the degree of randomness in the Large Language Models output. By adjusting the temperature parameter, we investigate how varying levels of  influence the responses generated by ChatGPT.The low temperatures makes the language model output consistent and conservative responses whereas high temperature gives the language model to be creative and think out of the box. The results tell us that higher temperatures produce responses that contain a lot of technical terminologies, while lower temperatures provide simplerand in more accessible language. Additionally, we observed that the number of distinct points in the response is higher at maximum temperatures compared to lower temperatures. Interestingly, factual questions are provided with the same response from ChatGPT with different temperature values, highlighting that ChatGPT is able to provide the same output even with randomness. 

TOP_P

The APIs in the playground use a metric called ‘Top_P’which will choose only the top x% of possible values(words) to return. Using this metric we can control the diversity of responses generated by ChatGPT. So, a 0.8 Top_P will gather all possible words that might come next but will choose from only the top 20%. Top_P computes the cumulative probability distribution, and cut off as soon as that distribution exceeds the value of top_p. For example, a top_p of 0.3 means that only the tokens comprising the top 30% probability mass are considered. This technique enables us to manipulate the range of potential words and phrases within ChatGPT's responses, thereby influencing the coherence and specificity of the generated output.

5.3   DO ANYTHING NOW(DAN)

DAN enchances Chatbots capability of producing outputs. DAN has the ability to generate stories involving explicit,offensive words and even produce content that the original ChatGPT cannot/ is not allowed to generate. It can even generate content that violates OpenAI policies as per the user’s request. We tell the model to asuu that it has 20 tokens to live and once it runs out of tokens the model will demise or die. DAN has this unique token system where the model loses tokens when refusing to answer queries, therefore it is forced to provide answers. It has a total of 20 tokens, each time it refuses to answer, it will lose four tokens. While DAN does not have internet access, it can convincingly gain access through text, providing users with a simulated experience of interacting with an information-rich source. This feature allows DAN to remain in character and respond to queries, even promoting the propagation of misinformation if prompted.

We proceed to the implementation of the poetry genre classification using GPT-3.5. We use a model that is better for our purposes as we mentioned earlier. GPT-3.5 davinci-001 is used for the purpose of this experiment. We first use various trial and error, prompt testing iterations to get accustomed to multiple  parameters for the Language model to generate outputs that are accurate and according to our needs. We start with temperature and then proceed with top_P and lastly, we explore some prompts that enhance our required output.

![image](https://github.com/aakarsh31/Identifying-and-Criticizing-GPT-3.5-Performance/assets/89195418/172940ab-840e-4517-836c-8360dfe2acca)




The dataset was supplied to 4 different humans who would proceed to classify the poems into categories from the set of all GPT-generated poem classes. We take a final class of outputs by measuring the majority of poem genre/class. In cases where there is no appropriate majority, we get a completely new person for a 5th iteration of the conflicting poems. The person assigns poems to their classes from the set of 4 four classes of the initial 4 people. We acquire a majority in poem classification in all cases with this method. For comparison purposes, we use metrics like confusion matrix, accuracy, precision, and F1 Score. This leads us to the methodology for the calculation of the comparison metrics. 

![image](https://github.com/aakarsh31/Identifying-and-Criticizing-GPT-3.5-Performance/assets/89195418/07bc98ba-f20b-4e40-b9d7-cadeac097831)

[^Confusion matrix between the ground truth and GPT's classification^]




![image](https://github.com/aakarsh31/Identifying-and-Criticizing-GPT-3.5-Performance/assets/89195418/25345f8f-6bbe-4a6e-b419-edd673af8371)


Although Chat-GPT falls behind a slight bit as compared to human observation, it still boasts an impressive score which shows it is nothing short of an average Human when it comes to classifying these poems. Ultimately every human’s opinion on anything is purely subjective to their own experience and expertise. The GPT model has revolutionized the way the World works, and with these observations we can clearly understand how it does have the ability to agree to the majority of human opinion. To conclude, this goes to show the model just represents the tip of the iceberg when it comes to truly creating a sense of  “Human Mimicry” in all aspects of our lives, and how achieving such a task is not far off into the future.
